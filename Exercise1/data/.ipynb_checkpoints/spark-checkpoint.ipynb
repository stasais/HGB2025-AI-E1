{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb7b86d-a806-4c53-8cd8-5a02447c16e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading people_big from PostgreSQL ===\n",
      "Rows loaded: 1000000\n",
      "Load time: 0.12 seconds\n",
      "\n",
      "=== Query (a): AVG salary per department ===\n",
      "+------------------+----------+\n",
      "|department        |avg_salary|\n",
      "+------------------+----------+\n",
      "|Workforce Planning|85090.82  |\n",
      "|Web Development   |84814.36  |\n",
      "|UX Design         |84821.2   |\n",
      "|UI Design         |85164.64  |\n",
      "|Treasury          |84783.27  |\n",
      "|Training          |85148.1   |\n",
      "|Tax               |85018.57  |\n",
      "|Sustainability    |85178.99  |\n",
      "|Supply Chain      |84952.89  |\n",
      "|Subscriptions     |84899.19  |\n",
      "+------------------+----------+\n",
      "\n",
      "Query (a) time: 0.59 seconds\n",
      "\n",
      "=== Query (b): Nested aggregation ===\n",
      "+------------+-----------------+\n",
      "|country     |avg_salary       |\n",
      "+------------+-----------------+\n",
      "|Egypt       |87382.229633112  |\n",
      "|Kuwait      |87349.3517377211 |\n",
      "|Saudi Arabia|87348.80512175433|\n",
      "|Panama      |87345.00623707911|\n",
      "|Denmark     |87328.03514120901|\n",
      "|Jamaica     |87305.437352083  |\n",
      "|Lebanon     |87292.76891750695|\n",
      "|Turkey      |87290.69043798617|\n",
      "|Malaysia    |87253.78746341489|\n",
      "|Kazakhstan  |87251.74274968785|\n",
      "+------------+-----------------+\n",
      "\n",
      "Query (b) time: 0.76 seconds\n",
      "\n",
      "=== Query (c): Top 10 salaries ===\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "|id    |first_name|last_name|gender|department      |salary|country     |\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "|764650|Tim       |Jensen   |Male  |Analytics       |160000|Bulgaria    |\n",
      "|10016 |Anastasia |Edwards  |Female|Analytics       |159998|Kuwait      |\n",
      "|754528|Adrian    |Young    |Male  |Game Analytics  |159997|UK          |\n",
      "|240511|Diego     |Lopez    |Male  |Game Analytics  |159995|Malaysia    |\n",
      "|893472|Mariana   |Cook     |Female|People Analytics|159995|South Africa|\n",
      "|359891|Mariana   |Novak    |Female|Game Analytics  |159992|Mexico      |\n",
      "|53102 |Felix     |Taylor   |Male  |Data Science    |159989|Bosnia      |\n",
      "|768143|Teresa    |Campbell |Female|Game Analytics  |159988|Spain       |\n",
      "|729165|Antonio   |Weber    |Male  |Analytics       |159987|Moldova     |\n",
      "|952549|Adrian    |Harris   |Male  |Analytics       |159986|Georgia     |\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "\n",
      "Query (c) time: 1.1 seconds\n",
      "\n",
      "=== Query (d): Heavy self-join COUNT (DANGEROUS) ===\n",
      "Join count: 10983941260\n",
      "Query (d) time: 5.44 seconds\n",
      "\n",
      "=== Query (d-safe): Join-equivalent rewrite ===\n",
      "+-----------+\n",
      "|total_pairs|\n",
      "+-----------+\n",
      "|10983941260|\n",
      "+-----------+\n",
      "\n",
      "Query (d-safe) time: 0.46 seconds\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0. Imports & Spark session\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import builtins  # <-- IMPORTANT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    round as spark_round,   # Spark round ONLY for Columns\n",
    "    count,\n",
    "    col,\n",
    "    sum as _sum\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"PostgresVsSparkBenchmark\")\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.2\")\n",
    "    .config(\"spark.eventLog.enabled\", \"true\")\n",
    "    .config(\"spark.eventLog.dir\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.history.fs.logDirectory\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .config(\"spark.default.parallelism\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# ============================================\n",
    "# 1. JDBC connection config\n",
    "# ============================================\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/postgres\"\n",
    "jdbc_props = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# 2. Load data from PostgreSQL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Loading people_big from PostgreSQL ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_big = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"people_big\",\n",
    "    properties=jdbc_props\n",
    ")\n",
    "\n",
    "# Force materialization\n",
    "row_count = df_big.count()\n",
    "\n",
    "print(f\"Rows loaded: {row_count}\")\n",
    "print(\"Load time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# Register temp view\n",
    "df_big.createOrReplaceTempView(\"people_big\")\n",
    "\n",
    "# ============================================\n",
    "# 3. Query (a): Simple aggregation\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (a): AVG salary per department ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_a = (\n",
    "    df_big\n",
    "    .groupBy(\"department\")\n",
    "    .agg(spark_round(avg(\"salary\"), 2).alias(\"avg_salary\"))\n",
    "    .orderBy(\"department\", ascending=False)\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_a.collect()\n",
    "q_a.show(truncate=False)\n",
    "print(\"Query (a) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 4. Query (b): Nested aggregation\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (b): Nested aggregation ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_b = spark.sql(\"\"\"\n",
    "SELECT country, AVG(avg_salary) AS avg_salary\n",
    "FROM (\n",
    "    SELECT country, department, AVG(salary) AS avg_salary\n",
    "    FROM people_big\n",
    "    GROUP BY country, department\n",
    ") sub\n",
    "GROUP BY country\n",
    "ORDER BY avg_salary DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "q_b.collect()\n",
    "q_b.show(truncate=False)\n",
    "print(\"Query (b) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 5. Query (c): Sorting + Top-N\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (c): Top 10 salaries ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_c = (\n",
    "    df_big\n",
    "    .orderBy(col(\"salary\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_c.collect()\n",
    "q_c.show(truncate=False)\n",
    "print(\"Query (c) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 6. Query (d): Heavy self-join (COUNT only)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (d): Heavy self-join COUNT (DANGEROUS) ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_d = (\n",
    "    df_big.alias(\"p1\")\n",
    "    .join(df_big.alias(\"p2\"), on=\"country\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "print(\"Join count:\", q_d)\n",
    "print(\"Query (d) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 7. Query (d-safe): Join-equivalent rewrite\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (d-safe): Join-equivalent rewrite ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grouped = df_big.groupBy(\"country\").agg(count(\"*\").alias(\"cnt\"))\n",
    "\n",
    "q_d_safe = grouped.select(\n",
    "    _sum(col(\"cnt\") * col(\"cnt\")).alias(\"total_pairs\")\n",
    ")\n",
    "\n",
    "q_d_safe.collect()\n",
    "q_d_safe.show()\n",
    "print(\"Query (d-safe) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 8. Cleanup\n",
    "# ============================================\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ccd33-bf40-456f-a44a-5a576ace64b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
